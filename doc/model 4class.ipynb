{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e13773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd8e52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43307, 5)\n",
      "0    12054\n",
      "1    10549\n",
      "2    10441\n",
      "3    10263\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/user_fake_authentic_4class.csv')\n",
    "x = df[['pos', 'cs', 'cl', 'erc', 'erl']]  # flg\n",
    "# pos: Number of total posts that the user has ever posted\n",
    "# cs: Average cosine similarity of between all pair of two posts a user has\n",
    "# cl: The average number of character of captions in media\n",
    "# erc: (num comments) divide by (num media) divide by (num followers)\n",
    "y_org = df['class']\n",
    "y = y_org.copy()\n",
    "y[y == 'a'] = 0\n",
    "y[y == 'i'] = 1\n",
    "y[y == 'r'] = 2\n",
    "y[y == 's'] = 3\n",
    "y = y.astype(np.int64)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6bf6368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10827, 5)\n",
      "0    3014\n",
      "1    2637\n",
      "2    2610\n",
      "3    2566\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,\n",
    "                                                 y,\n",
    "                                                 train_size=.75,\n",
    "                                                 test_size=.25,\n",
    "                                                 stratify=y, # maintain label proportions\n",
    "                                                 random_state=0\n",
    "                                                )\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ff37e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = pd.DataFrame(scaler.fit_transform(x_train))\n",
    "x_test = pd.DataFrame(scaler.fit_transform(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43db82da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 as evaluation metric\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75e2e3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6251962685877898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62      3014\n",
      "           1       0.54      0.99      0.70      2637\n",
      "           2       0.77      0.18      0.29      2610\n",
      "           3       0.77      0.71      0.74      2566\n",
      "\n",
      "    accuracy                           0.63     10827\n",
      "   macro avg       0.68      0.62      0.59     10827\n",
      "weighted avg       0.67      0.63      0.59     10827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=10)\n",
    "gbc.fit(x_train, y_train)\n",
    "\n",
    "y_pred_gbc = gbc.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_gbc))\n",
    "print(classification_report(y_test, y_pred_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61b5b9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28950    0\n",
      "4933     2\n",
      "40133    0\n",
      "35177    1\n",
      "9811     2\n",
      "        ..\n",
      "28959    0\n",
      "22794    3\n",
      "16134    3\n",
      "16316    3\n",
      "1462     2\n",
      "Name: class, Length: 32480, dtype: int64\n",
      "       1  2  3\n",
      "28950  0  0  0\n",
      "4933   0  1  0\n",
      "40133  0  0  0\n",
      "35177  1  0  0\n",
      "9811   0  1  0\n",
      "...   .. .. ..\n",
      "28959  0  0  0\n",
      "22794  0  0  1\n",
      "16134  0  0  1\n",
      "16316  0  0  1\n",
      "1462   0  1  0\n",
      "\n",
      "[32480 rows x 3 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (32480, 3) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m y_test_d \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(y_test)\n\u001b[1;32m      5\u001b[0m gbc1 \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mgbc1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m y_pred_gbc1 \u001b[38;5;241m=\u001b[39m gbc1\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(y_test, y_pred_gbc1))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/eods-s22/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:420\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    416\u001b[0m sample_weight_is_none \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    418\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n\u001b[0;32m--> 420\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    423\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_y(y, sample_weight)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/eods-s22/lib/python3.9/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[38;5;241m-\u001b[39mextra_args:])]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/eods-s22/lib/python3.9/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    915\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    916\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected. Please change the shape of y to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(n_samples, ), for example using ravel().\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    918\u001b[0m                       DataConversionWarning, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mravel(y)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape))\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (32480, 3) instead."
     ]
    }
   ],
   "source": [
    "y_train_d = pd.get_dummies(y_train, drop_first=True)\n",
    "print(y_train)\n",
    "print(y_train_d)\n",
    "y_test_d = pd.get_dummies(y_test)\n",
    "gbc1 = GradientBoostingClassifier(n_estimators=10)\n",
    "gbc1.fit(x_train, y_train_d)\n",
    "\n",
    "y_pred_gbc1 = gbc1.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_gbc1))\n",
    "print(classification_report(y_test, y_pred_gbc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "136def13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5177796250115452\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.73      0.58      3014\n",
      "           1       0.51      0.94      0.66      2637\n",
      "           2       0.76      0.14      0.23      2610\n",
      "           3       0.62      0.23      0.33      2566\n",
      "\n",
      "    accuracy                           0.52     10827\n",
      "   macro avg       0.59      0.51      0.45     10827\n",
      "weighted avg       0.59      0.52      0.46     10827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logr = LogisticRegression(multi_class='ovr', # default\n",
    "                          max_iter=1000)     # to avoid timeout errors\n",
    "logr.fit(x_train, y_train)\n",
    "\n",
    "y_pred_logr = logr.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_logr))\n",
    "print(classification_report(y_test, y_pred_logr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "395a6e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6287983744342847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.68      0.62      3014\n",
      "           1       0.68      0.89      0.77      2637\n",
      "           2       0.61      0.27      0.37      2610\n",
      "           3       0.65      0.67      0.66      2566\n",
      "\n",
      "    accuracy                           0.63     10827\n",
      "   macro avg       0.63      0.63      0.61     10827\n",
      "weighted avg       0.63      0.63      0.61     10827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7c5015e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6066315692250854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.52      0.56      3014\n",
      "           1       0.56      0.95      0.70      2637\n",
      "           2       0.64      0.29      0.40      2610\n",
      "           3       0.68      0.68      0.68      2566\n",
      "\n",
      "    accuracy                           0.61     10827\n",
      "   macro avg       0.62      0.61      0.58     10827\n",
      "weighted avg       0.62      0.61      0.58     10827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc_md5 = DecisionTreeClassifier(max_depth=5) # max_depth: max number of questions\n",
    "dtc_md5.fit(x_train, y_train)\n",
    "\n",
    "y_pred_dtc_md5 = dtc_md5.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_dtc_md5))\n",
    "print(classification_report(y_test, y_pred_dtc_md5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dae5e294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5567562575043872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.37      0.45      3014\n",
      "           1       0.54      0.97      0.69      2637\n",
      "           2       0.56      0.21      0.31      2610\n",
      "           3       0.58      0.71      0.63      2566\n",
      "\n",
      "    accuracy                           0.56     10827\n",
      "   macro avg       0.56      0.56      0.52     10827\n",
      "weighted avg       0.56      0.56      0.52     10827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, # number of trees in ensemble\n",
    "                             n_jobs=-1,       # parallelize using all available cores\n",
    "                             random_state=0   # for demonstration only\n",
    "                            )\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "y_pred_rfc = rfc.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_rfc))\n",
    "print(classification_report(y_test, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de147369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47677103537452664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.53      0.47      3014\n",
      "           1       0.51      0.90      0.65      2637\n",
      "           2       0.20      0.09      0.13      2610\n",
      "           3       0.78      0.37      0.50      2566\n",
      "\n",
      "    accuracy                           0.48     10827\n",
      "   macro avg       0.48      0.47      0.44     10827\n",
      "weighted avg       0.48      0.48      0.44     10827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(x_train, y_train)\n",
    "\n",
    "y_pred_ada = ada.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_ada))\n",
    "print(classification_report(y_test, y_pred_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf47c72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76336935, 0.76577076, 0.76741179])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(gbc, x_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# cross_val_score(gbc, x_train, y_train, cv=3, scoring=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f751287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9916  160 1938   40]\n",
      " [ 273 9544  695   37]\n",
      " [1609 1126 5956 1750]\n",
      " [2023  219  832 7189]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAEBCAYAAABRzrhTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAJ80lEQVR4nO3dS4id5RnA8X/uEYk4ONGAl8nC6ZupggsTHFGhIC6ieKnUbqyUgEgXBV2IMWJcKSEL3VQUaolIsRS8RAVBhJAiKlOmGxEZH5JAIiOok3jrxDhJxukiKc0ik3Niv+89mfP8f7uTOZzn+RZ/v3Mmx7yL5ubmkNTfFvd6AUntM3QpAUOXEjB0KQFDlxIwdCmBpb1e4OcopSwGngOuAWaA+yNib2+3al4p5Tpge0T8qte7NKmUsgzYAawFVgBPRsRbPV2qQaWUJcALQAFmgU0Rsa+XOy3UO/pdwMqIuB54FHi6t+s0r5TyCPAXYGWvd2nB74BDEXETsBF4tsf7NO12gIi4AXgCeKa36yzc0G8E3gGIiDFgfW/XacU+4O5eL9GSV4Ctpzw+3qtF2hARbwAPnHw4BHzZu21OWKihXwB8d8rj2VLKgvwYMp+IeA041us92hAR0xHx71LKKuBV4PFe79S0iDheSnkJ+BMnrrGnFmro3wOrTnm8OCL66q7Q70oplwO7gb9GxN96vU8bIuL3wC+AF0op5/dyl4Ua+gfArQCllFHg496uo7NRSrkEeBfYHBE7er1P00op95VStpx8+APwEyd+KdczC/Xt7k7gllLKh8AiYFOP99HZeQwYALaWUv77WX1jRBzp4U5Neh14sZTyHrAMeCgifuzlQov8v9ek/rdQ37pLOguGLiVg6FIChi4lYOhSAgs+9FLKA52ftXD18/X187XBuXV9Cz50/ved4n7Vz9fXz9cG59D19UPokjpo/AszU1NTcwcOHGj0Nc/k4osv5quvvqo2b8mSJdVmAQwODnLw4MFq80op1WYdPnyY88+v+xXwiYmJarNWr17N1NRUtXlDQ0MMDg4uOt3PGv8K7IEDB9iwYUPTLzuv8fHxqvMGBgaqzQLYtWsXN998c7V5u3fvrjZreHiYPXv2VJsHMDo6Wm3W2NhY9XmDg4On/Zlv3aUEDF1KwNClBAxdSsDQpQQMXUrA0KUEDF1KwNClBAxdSsDQpQQMXUrA0KUEDF1KwNClBAxdSsDQpQQMXUrA0KUEDF1KwNClBAxdSsDQpQQ6/rvupZTFwHPANcAMcH9E7G17MUnN6eaOfhewMiKuBx4Fnm51I0mN6yb0G4F3ACJiDFjf6kaSGtfNkUwXAN+d8ni2lLI0Io6f7slDQ0OMj483slw3RkZGqs6rffZaKYVdu3ZVmzc8PFxt1ooVK6rOgxPHFtWybt26qvPOpJvQvwdWnfJ48XyRg2evNc2z15rV72evzaebt+4fALcClFJGgY+bWUtSLd3c0XcCt5RSPgQWAZvaXUlS0zqGHhE/AX+osIuklviFGSkBQ5cSMHQpAUOXEjB0KQFDlxIwdCkBQ5cSMHQpAUOXEjB0KQFDlxIwdCkBQ5cSMHQpAUOXEjB0KQFDlxIwdCkBQ5cSMHQpAUOXEujm33U/K8uXL2ft2rVNv+w5M2///v3VZgHMzs7yzTffVJv31FNPVZu1bdu2qvMy844uJWDoUgKGLiVg6FIChi4lYOhSAoYuJWDoUgKGLiVg6FIChi4lYOhSAoYuJWDoUgKGLiVg6FIChi4lYOhSAoYuJWDoUgKGLiVg6FIChi4lYOhSAl2FXkq5rpTyj5Z3kdSSjie1lFIeAe4DDre/jqQ2dHNH3wfc3fYiktrTMfSIeA04VmEXSS1ZNDc31/FJpZS1wN8jYrTTc7/++uu5ycnJBlbrzpVXXsnevXurzTt69Gi1WQAjIyNMTExUmzcwMFBt1qWXXsrnn39ebR7At99+W23WunXr+PTTT6vNA7j22msXne7PGz9NdXJykjvvvLPpl53Xm2++WXVe7dNUx8fH2bBhQ7V599xzT7VZ27ZtY8uWLdXmAezcubParLGxMUZHO94bG503H/96TUqgqzt6ROwH6v2nSVKjvKNLCRi6lIChSwkYupSAoUsJGLqUgKFLCRi6lIChSwkYupSAoUsJGLqUgKFLCRi6lIChSwkYupSAoUsJGLqUgKFLCRi6lIChSwkYupSAoUsJdHUk09mYnp6e++STTxp9zTO56qqrqDnv/fffrzYL4N577+Xll1+uNu/hhx+uNqv2KTQAEVFt1hVXXMFnn31Wdd7KlStPeySTd3QpAUOXEjB0KQFDlxIwdCkBQ5cSMHQpAUOXEjB0KQFDlxIwdCkBQ5cSMHQpAUOXEjB0KQFDlxIwdCkBQ5cSMHQpAUOXEjB0KQFDlxIwdCkBQ5cSWHqmH5ZSlgE7gLXACuDJiHirwl6SGtTpjv474FBE3ARsBJ5tfyVJTTvjHR14BXj1lMfHW9xFUkvOGHpETAOUUlZxIvjHaywlqVkdD1kspVwO7ASei4gdnV7w2LFjczMzMw2t19l5553HkSNHqs2bnp6uNgvgoosu4tChQ9XmTU5OVps1MjLCxMREtXkAV199dbVZy5cv5+jRo9XmAfMestjpl3GXAO8Cf4yIXd0MmpmZqXq6qaepNsvTVJvTi9NU59PpM/pjwACwtZSy9eSfbYyIerdQSf+3Tp/RHwQerLSLpJb4hRkpAUOXEjB0KQFDlxIwdCkBQ5cSMHQpAUOXEjB0KQFDlxIwdCkBQ5cSMHQpAUOXEjB0KQFDlxIwdCkBQ5cSMHQpAUOXEjB0KQFDlxIwdCmBjkcy/QyNv+C55LLLLqs67+233+a2226rNu+OO+6oNmvz5s1s37692jyA559/vtqs2ifRjI+Ps379+tMeyeQdXUrA0KUEDF1KwNClBAxdSsDQpQQMXUrA0KUEDF1KwNClBAxdSsDQpQQMXUrA0KUEDF1KwNClBAxdSsDQpQQMXUrA0KUEDF1KwNClBAxdSsDQpQSWdnpCKWUJ8AJQgFlgU0Tsa3sxSc3p5o5+O0BE3AA8ATzT6kaSGtcx9Ih4A3jg5MMh4Ms2F5LUvK7PXiulvAT8GvhNRLx7hqf29dlrH330UdV5w8PD7Nmzp9q8Cy+8sNqsNWvW8MUXX1SbBzA1NVVt1sjICBMTE9XmAfOevXZWhyyWUtYA/wR+GRGH53laX4fuIYvN8ZDF5uf97EMWSyn3lVK2nHz4A/ATJ34pJ2mB6Phbd+B14MVSynvAMuChiPix3bUkNalj6Cffov+2wi6SWuIXZqQEDF1KwNClBAxdSsDQpQQMXUrA0KUEDF1KwNClBAxdSsDQpQQMXUrA0KUEDF1KwNClBAxdSsDQpQQMXUrA0KUEDF1KwNClBAxdSsDQpQTO6kimLk0BB5p+0XmHTU0Nrl69+mCtebX18/X187VBT65vCFh9uh+0EXpVpZR/RcT6Xu/Rln6+vn6+Nji3rs+37lIChi4l0A+h/7nXC7Ssn6+vn68NzqHrW/Cf0SV11g93dEkdGLqUgKFLCRi6lIChSwn8B37iRAA8nGoDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = cross_val_predict(gbc, x, y, cv=3)\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(cm)\n",
    "\n",
    "row_sums = cm.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = cm / row_sums\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1b44bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recalls:\n",
      "factive fake user: 0.905\n",
      "inactive fake user: 0.570\n",
      "spammer fake user: 0.700\n"
     ]
    }
   ],
   "source": [
    "# print('Precisions:')\n",
    "# print(f'for 0: {(cm.iloc[0,0] / sum(cm.iloc[:,0])):.3f}')\n",
    "# print(f'for 1: {(cm.iloc[1,1] / sum(cm.iloc[:,1])):.3f}')\n",
    "# print(f'for 2: {(cm.iloc[2,2] / sum(cm.iloc[:,2])):.3f}')\n",
    "# print(f'for 3: {(cm.iloc[3,3] / sum(cm.iloc[:,3])):.3f}')\n",
    "\n",
    "print('Recalls:')\n",
    "# print(f'for 0: {(cm.iloc[0,0] / sum(cm.iloc[0,:])):.3f}')\n",
    "print(f'factive fake user: {(cm[1,1] / sum(cm[1,:])):.3f}')\n",
    "print(f'inactive fake user: {(cm[2,2] / sum(cm[2,:])):.3f}')\n",
    "print(f'spammer fake user: {(cm[3,3] / sum(cm[3,:])):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31a4af0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inactive fake user is misclassified.\n"
     ]
    }
   ],
   "source": [
    "print('Inactive fake user is misclassified.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c0e5a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37974755 0.09690667 0.32284323 0.13534112 0.06516142]\n"
     ]
    }
   ],
   "source": [
    "print(gbc.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dd12760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators': np.arange(10, 300, 10),\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 1]\n",
    "}\n",
    "classes = y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89b8adce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are:  {'learning_rate': 0.1, 'n_estimators': 130}\n"
     ]
    }
   ],
   "source": [
    "grid_clf = GridSearchCV(estimator=gbc, scoring='f1_weighted', param_grid=params, cv=5)\n",
    "grid_clf.fit(x_train, y_train)\n",
    "\n",
    "print(\"The best parameters are: \", grid_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35eb461",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred_grid \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_clf\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(y_test, y_pred_grid))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_grid))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_clf' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred_grid = grid_clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_grid))\n",
    "print(classification_report(y_test, y_pred_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114a56fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eods-s22",
   "language": "python",
   "name": "eods-s22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
